import whisper
import torch
from transformers import pipeline
import re
from datetime import datetime
import os
from gpt import callGPT  # Import the callGPT function from gpt.py

# Check if CUDA (GPU) is available
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using device: {device}")

# Load Whisper Model (use "medium" for better multilingual support)
model = whisper.load_model("medium", device=device)

# Load Sentiment Analysis Model with GPU support
sentiment_analyzer = pipeline("sentiment-analysis", device=device)

# Load Zero-Shot Classifier with GPU support
classifier = pipeline("zero-shot-classification", device=device)

def extract_personal_info(transcribed_text, language='english'):
    """Extracts personal information from the transcribed text using GPT API."""
    
    # Prepare system prompt based on language
    system_prompts = {
        'english': """You are an AI assistant helping with information extraction from a First Information Report (FIR) or police complaint transcript. 
Extract all relevant personal information and incident details in a structured format. Be precise and extract only what is explicitly stated in the text.""",
        
        'hindi': """‡§Ü‡§™ ‡§è‡§ï AI ‡§∏‡§π‡§æ‡§Ø‡§ï ‡§π‡•à‡§Ç ‡§ú‡•ã ‡§™‡•ç‡§∞‡§•‡§Æ ‡§∏‡•Ç‡§ö‡§®‡§æ ‡§∞‡§ø‡§™‡•ã‡§∞‡•ç‡§ü (FIR) ‡§Ø‡§æ ‡§™‡•Å‡§≤‡§ø‡§∏ ‡§∂‡§ø‡§ï‡§æ‡§Ø‡§§ ‡§∏‡•á ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§®‡§ø‡§ï‡§æ‡§≤‡§®‡•á ‡§Æ‡•á‡§Ç ‡§Æ‡§¶‡§¶ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç‡•§ 
‡§∏‡§Ç‡§∞‡§ö‡§ø‡§§ ‡§™‡•ç‡§∞‡§æ‡§∞‡•Ç‡§™ ‡§Æ‡•á‡§Ç ‡§∏‡§≠‡•Ä ‡§™‡•ç‡§∞‡§æ‡§∏‡§Ç‡§ó‡§ø‡§ï ‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§‡§ø‡§ó‡§§ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§î‡§∞ ‡§ò‡§ü‡§®‡§æ ‡§µ‡§ø‡§µ‡§∞‡§£ ‡§®‡§ø‡§ï‡§æ‡§≤‡•á‡§Ç‡•§ ‡§∏‡§ü‡•Ä‡§ï ‡§∞‡§π‡•á‡§Ç ‡§î‡§∞ ‡§ï‡•á‡§µ‡§≤ ‡§µ‡§π‡•Ä ‡§®‡§ø‡§ï‡§æ‡§≤‡•á‡§Ç ‡§ú‡•ã ‡§™‡§æ‡§† ‡§Æ‡•á‡§Ç ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§¨‡§§‡§æ‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§""",
        
        'punjabi': """‡®§‡©Å‡®∏‡©Ä‡®Ç ‡®á‡©±‡®ï AI ‡®∏‡®π‡®æ‡®á‡®ï ‡®π‡©ã ‡®ú‡©ã ‡®™‡®π‡®ø‡®≤‡©Ä ‡®∏‡©Ç‡®ö‡®®‡®æ ‡®∞‡®ø‡®™‡©ã‡®∞‡®ü (FIR) ‡®ú‡®æ‡®Ç ‡®™‡©Å‡®≤‡®ø‡®∏ ‡®∏‡®º‡®ø‡®ï‡®æ‡®á‡®§ ‡®§‡©ã‡®Ç ‡®ú‡®æ‡®£‡®ï‡®æ‡®∞‡©Ä ‡®ï‡©±‡®¢‡®£ ‡®µ‡®ø‡©±‡®ö ‡®∏‡®π‡®æ‡®á‡®§‡®æ ‡®ï‡®∞ ‡®∞‡®π‡©á ‡®π‡©ã‡•§
‡®∏‡©∞‡®∞‡®ö‡®ø‡®§ ‡®´‡®æ‡®∞‡®Æ‡©à‡®ü ‡®µ‡®ø‡©±‡®ö ‡®∏‡®æ‡®∞‡©Ä ‡®¢‡©Å‡®ï‡®µ‡©Ä‡®Ç ‡®®‡®ø‡©±‡®ú‡©Ä ‡®ú‡®æ‡®£‡®ï‡®æ‡®∞‡©Ä ‡®Ö‡®§‡©á ‡®ò‡®ü‡®®‡®æ ‡®¶‡©á ‡®µ‡©á‡®∞‡®µ‡©á ‡®ï‡©±‡®¢‡©ã‡•§ ‡®∏‡®ü‡©Ä‡®ï ‡®∞‡®π‡©ã ‡®Ö‡®§‡©á ‡®∏‡®ø‡®∞‡®´ ‡®â‡®π‡©Ä ‡®ï‡©±‡®¢‡©ã ‡®ú‡©ã ‡®ü‡©à‡®ï‡®∏‡®ü ‡®µ‡®ø‡©±‡®ö ‡®∏‡®™‡®∏‡®º‡®ü ‡®§‡©å‡®∞ '‡®§‡©á ‡®ï‡®ø‡®π‡®æ ‡®ó‡®ø‡®Ü ‡®π‡©à‡•§"""
    }
    
    # Prepare user prompt
    user_prompts = {
        'english': f"""Extract the following information from the text below and provide it in a structured JSON format with these keys:
- victim_name
- father_or_husband_name
- dob (date of birth)
- nationality
- occupation
- address
- incident_date
- incident_time
- incident_location
- witness_details
- accused_description
- stolen_properties
- total_value
- delay_reason
- incident_details (summary of the incident)

If information for any field is not available, provide an empty string for that field.

TEXT:
{transcribed_text}""",

        'hindi': f"""‡§®‡•Ä‡§ö‡•á ‡§¶‡§ø‡§è ‡§ó‡§è ‡§™‡§æ‡§† ‡§∏‡•á ‡§®‡§ø‡§Æ‡•ç‡§®‡§≤‡§ø‡§ñ‡§ø‡§§ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§®‡§ø‡§ï‡§æ‡§≤‡•á‡§Ç ‡§î‡§∞ ‡§á‡§∏‡•á ‡§á‡§® ‡§ï‡•Å‡§Ç‡§ú‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§∏‡§æ‡§• ‡§è‡§ï ‡§∏‡§Ç‡§∞‡§ö‡§ø‡§§ JSON ‡§™‡•ç‡§∞‡§æ‡§∞‡•Ç‡§™ ‡§Æ‡•á‡§Ç ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡•á‡§Ç:
- victim_name (‡§™‡•Ä‡§°‡§º‡§ø‡§§ ‡§ï‡§æ ‡§®‡§æ‡§Æ)
- father_or_husband_name (‡§™‡§ø‡§§‡§æ ‡§Ø‡§æ ‡§™‡§§‡§ø ‡§ï‡§æ ‡§®‡§æ‡§Æ)
- dob (‡§ú‡§®‡•ç‡§Æ ‡§§‡§ø‡§•‡§ø)
- nationality (‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø‡§§‡§æ)
- occupation (‡§µ‡•ç‡§Ø‡§µ‡§∏‡§æ‡§Ø)
- address (‡§™‡§§‡§æ)
- incident_date (‡§ò‡§ü‡§®‡§æ ‡§ï‡•Ä ‡§§‡§æ‡§∞‡•Ä‡§ñ)
- incident_time (‡§ò‡§ü‡§®‡§æ ‡§ï‡§æ ‡§∏‡§Æ‡§Ø)
- incident_location (‡§ò‡§ü‡§®‡§æ ‡§∏‡•ç‡§•‡§≤)
- witness_details (‡§ó‡§µ‡§æ‡§π ‡§µ‡§ø‡§µ‡§∞‡§£)
- accused_description (‡§Ü‡§∞‡•ã‡§™‡•Ä ‡§ï‡§æ ‡§µ‡§ø‡§µ‡§∞‡§£)
- stolen_properties (‡§ö‡•ã‡§∞‡•Ä ‡§ï‡•Ä ‡§∏‡§Ç‡§™‡§§‡•ç‡§§‡§ø)
- total_value (‡§ï‡•Å‡§≤ ‡§Æ‡•Ç‡§≤‡•ç‡§Ø)
- delay_reason (‡§¶‡•á‡§∞‡•Ä ‡§ï‡§æ ‡§ï‡§æ‡§∞‡§£)
- incident_details (‡§ò‡§ü‡§®‡§æ ‡§ï‡§æ ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂)

‡§Ø‡§¶‡§ø ‡§ï‡§ø‡§∏‡•Ä ‡§≠‡•Ä ‡§´‡§º‡•Ä‡§≤‡•ç‡§° ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à, ‡§§‡•ã ‡§â‡§∏ ‡§´‡§º‡•Ä‡§≤‡•ç‡§° ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ñ‡§æ‡§≤‡•Ä ‡§∏‡•ç‡§ü‡•ç‡§∞‡§ø‡§Ç‡§ó ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡•á‡§Ç‡•§

‡§™‡§æ‡§†:
{transcribed_text}""",

        'punjabi': f"""‡®π‡©á‡®†‡®æ‡®Ç ‡®¶‡®ø‡©±‡®§‡©á ‡®ü‡©à‡®ï‡®∏‡®ü ‡®§‡©ã‡®Ç ‡®π‡©á‡®† ‡®≤‡®ø‡®ñ‡©Ä ‡®ú‡®æ‡®£‡®ï‡®æ‡®∞‡©Ä ‡®ï‡©±‡®¢‡©ã ‡®Ö‡®§‡©á ‡®á‡®∏‡®®‡©Ç‡©∞ ‡®á‡®π‡®®‡®æ‡®Ç ‡®ï‡©Å‡©∞‡®ú‡©Ä‡®Ü‡®Ç ‡®®‡®æ‡®≤ ‡®á‡©±‡®ï ‡®∏‡©∞‡®∞‡®ö‡®ø‡®§ JSON ‡®´‡®æ‡®∞‡®Æ‡©à‡®ü ‡®µ‡®ø‡©±‡®ö ‡®™‡©ç‡®∞‡®¶‡®æ‡®® ‡®ï‡®∞‡©ã:
- victim_name (‡®™‡©Ä‡©ú‡®§ ‡®¶‡®æ ‡®®‡®æ‡®Æ)
- father_or_husband_name (‡®™‡®ø‡®§‡®æ ‡®ú‡®æ‡®Ç ‡®™‡®§‡©Ä ‡®¶‡®æ ‡®®‡®æ‡®Æ)
- dob (‡®ú‡®®‡®Æ ‡®Æ‡®ø‡®§‡©Ä)
- nationality (‡®®‡®æ‡®ó‡®∞‡®ø‡®ï‡®§‡®æ)
- occupation (‡®ï‡®ø‡©±‡®§‡®æ)
- address (‡®™‡®§‡®æ)
- incident_date (‡®ò‡®ü‡®®‡®æ ‡®¶‡©Ä ‡®Æ‡®ø‡®§‡©Ä)
- incident_time (‡®ò‡®ü‡®®‡®æ ‡®¶‡®æ ‡®∏‡®Æ‡®æ‡®Ç)
- incident_location (‡®ò‡®ü‡®®‡®æ ‡®∏‡®•‡®æ‡®®)
- witness_details (‡®ó‡®µ‡®æ‡®π ‡®µ‡©á‡®∞‡®µ‡©á)
- accused_description (‡®¶‡©ã‡®∏‡®º‡©Ä ‡®¶‡®æ ‡®µ‡©á‡®∞‡®µ‡®æ)
- stolen_properties (‡®ö‡©ã‡®∞‡©Ä ‡®π‡©ã‡®à ‡®ú‡®æ‡®á‡®¶‡®æ‡®¶)
- total_value (‡®ï‡©Å‡©±‡®≤ ‡®Æ‡©Å‡©±‡®≤)
- delay_reason (‡®¶‡©á‡®∞‡©Ä ‡®¶‡®æ ‡®ï‡®æ‡®∞‡®®)
- incident_details (‡®ò‡®ü‡®®‡®æ ‡®¶‡®æ ‡®∏‡®æ‡®∞)

‡®ú‡©á‡®ï‡®∞ ‡®ï‡®ø‡®∏‡©á ‡®µ‡©Ä ‡®´‡©Ä‡®≤‡®° ‡®≤‡®à ‡®ú‡®æ‡®£‡®ï‡®æ‡®∞‡©Ä ‡®â‡®™‡®≤‡®¨‡®ß ‡®®‡®π‡©Ä‡®Ç ‡®π‡©à, ‡®§‡®æ‡®Ç ‡®â‡®∏ ‡®´‡©Ä‡®≤‡®° ‡®≤‡®à ‡®ñ‡®æ‡®≤‡©Ä ‡®∏‡®ü‡®∞‡®ø‡©∞‡®ó ‡®™‡©ç‡®∞‡®¶‡®æ‡®® ‡®ï‡®∞‡©ã‡•§

‡®ü‡©à‡®ï‡®∏‡®ü:
{transcribed_text}"""
    }
    
    try:
        # Select prompts based on language (default to English if language not found)
        system_prompt = system_prompts.get(language.lower(), system_prompts['english'])
        user_prompt = user_prompts.get(language.lower(), user_prompts['english'])
        
        # Call GPT API
        response = callGPT(system_prompt, user_prompt)
        
        # Parse the JSON response
        import json
        
        # Check if the response contains a JSON block
        if '{' in response and '}' in response:
            # Extract JSON content if it's embedded in other text
            json_start = response.find('{')
            json_end = response.rfind('}') + 1
            json_str = response[json_start:json_end]
            
            try:
                extracted_info = json.loads(json_str)
                
                # Ensure all expected fields are present
                expected_fields = [
                    "victim_name", "father_or_husband_name", "dob", "nationality", 
                    "occupation", "address", "incident_date", "incident_time", 
                    "incident_location", "witness_details", "accused_description", 
                    "stolen_properties", "total_value", "delay_reason", "incident_details"
                ]
                
                for field in expected_fields:
                    if field not in extracted_info:
                        extracted_info[field] = ""
                
                return extracted_info
                
            except json.JSONDecodeError:
                # If JSON parsing fails, fall back to regex-based extraction
                print("JSON parsing failed, falling back to regex extraction")
                return fallback_extract_personal_info(transcribed_text, language)
        else:
            # If no JSON in response, fall back to regex-based extraction
            print("No JSON found in response, falling back to regex extraction")
            return fallback_extract_personal_info(transcribed_text, language)
            
    except Exception as e:
        print(f"GPT extraction failed with error: {str(e)}")
        # Fall back to regex-based extraction
        return fallback_extract_personal_info(transcribed_text, language)


def fallback_extract_personal_info(transcribed_text, language='english'):
    """Fallback function that extracts personal information using regex patterns."""
    info = {
        "victim_name": "",
        "father_or_husband_name": "",
        "dob": "",
        "nationality": "",
        "occupation": "",
        "address": "",
        "incident_date": "",
        "incident_time": "",
        "incident_location": "",
        "witness_details": "",
        "accused_description": "",
        "stolen_properties": "",
        "total_value": "",
        "delay_reason": "",
        "incident_details": transcribed_text
    }
    
    # Language-specific patterns
    patterns = {
        'english': {
            'name': r"(?:my name is|I am|I'm|name:?\s+is|myself)\s+([A-Za-z\s]+?)(?:[\.,]|\s+and|\s+aged|\s+living)",
            'father': r"(?:my father's name is|father'?s? name:?\s+is|father is|my father,)\s+([A-Za-z\s]+?)(?:[\.,]|and)",
            'husband': r"(?:my husband's name is|husband'?s? name:?\s+is|husband is|my husband,)\s+([A-Za-z\s]+?)(?:[\.,]|and)",
            'dob': r"(?:born on|date of birth|dob:?|born|birth date)(?:\s+is)?\s+([0-9]{1,2}(?:st|nd|rd|th)?\s+(?:January|February|March|April|May|June|July|August|September|October|November|December|Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sept?|Oct|Nov|Dec)(?:\s+[0-9]{4})?)",
            'nationality': r"(?:my nationality is|nationality:?|I am a citizen of|citizen of)\s+([A-Za-z]+)",
            'occupation': r"(?:(?:I am|I'm|working as)(?: a| an)?\s+|occupation:?\s+|by profession,?\s+(?:I am|I'm)(?: a| an)?\s+|employed as(?: a| an)?\s+)([^.,]{3,30})(?:[\.,]|and|at)",
            'address': r"(?:I live at|address:?|residing at|residence:?|staying at)\s+([^.]{10,100})(?:\.|\n)",
            'location': r"(?:incident|crime|theft|attack|robbery) (?:occurred|happened|took place) (?:at|in|near|around)\s+([^\.]+?)(?:on|at|when|where|\.|\band\b)",
            'witness': r"([A-Za-z\s]+)(?:saw|witnessed|observed|was present)",
            'accused': r"(?:The accused|perpetrator|suspect|attacker|thief) (?:was|were|is|appeared to be|looked like|had|wore|was wearing)\s+([^\.]{5,100})(?:\.|\n)",
            'stolen': r"(?:stole|took|robbed|snatched|made away with|fled with|missing items include)\s+([^\.]{5,100})(?:\.|\n)",
            'value': r"(?:valued at|worth|amounting to|costing|estimated value of|total value)\s+(?:Rs\.?|‚Çπ|INR)?\s*([0-9,]+)"
        },
        'hindi': {
            'name': r"(?:‡§Æ‡•á‡§∞‡§æ ‡§®‡§æ‡§Æ|‡§Æ‡•à‡§Ç)\s+([^\.\,]+)[\.\,]",
            'father': r"(?:‡§Æ‡•á‡§∞‡•á ‡§™‡§ø‡§§‡§æ ‡§ï‡§æ ‡§®‡§æ‡§Æ|‡§™‡§ø‡§§‡§æ ‡§ï‡§æ ‡§®‡§æ‡§Æ|‡§™‡§ø‡§§‡§æ ‡§ú‡•Ä ‡§ï‡§æ ‡§®‡§æ‡§Æ)\s+([^\.\,]+)[\.\,]",
            'husband': r"(?:‡§Æ‡•á‡§∞‡•á ‡§™‡§§‡§ø ‡§ï‡§æ ‡§®‡§æ‡§Æ|‡§™‡§§‡§ø ‡§ï‡§æ ‡§®‡§æ‡§Æ)\s+([^\.\,]+)[\.\,]",
            'dob': r"(?:‡§ú‡§®‡•ç‡§Æ ‡§§‡§ø‡§•‡§ø|‡§ú‡§®‡•ç‡§Æ ‡§¶‡§ø‡§®‡§æ‡§Ç‡§ï)\s+([0-9]{1,2}\s+(?:‡§ú‡§®‡§µ‡§∞‡•Ä|‡§´‡§∞‡§µ‡§∞‡•Ä|‡§Æ‡§æ‡§∞‡•ç‡§ö|‡§Ö‡§™‡•ç‡§∞‡•à‡§≤|‡§Æ‡§à|‡§ú‡•Ç‡§®|‡§ú‡•Å‡§≤‡§æ‡§à|‡§Ö‡§ó‡§∏‡•ç‡§§|‡§∏‡§ø‡§§‡§Ç‡§¨‡§∞|‡§Ö‡§ï‡•ç‡§ü‡•Ç‡§¨‡§∞|‡§®‡§µ‡§Ç‡§¨‡§∞|‡§¶‡§ø‡§∏‡§Ç‡§¨‡§∞)(?:\s+[0-9]{4})?)",
            'nationality': r"(?:‡§Æ‡•á‡§∞‡•Ä ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø‡§§‡§æ|‡§®‡§æ‡§ó‡§∞‡§ø‡§ï‡§§‡§æ)\s+([^\.\,]+)",
            'occupation': r"(?:‡§Æ‡•à‡§Ç|‡§Æ‡•á‡§∞‡§æ ‡§™‡•á‡§∂‡§æ|‡§µ‡•ç‡§Ø‡§µ‡§∏‡§æ‡§Ø)\s+([^\.\,]{3,30})(?:‡§π‡•Ç‡§Å|‡§π‡•Ç‡§Ç|‡§π‡•à|‡§Æ‡•á‡§Ç|‡§ï‡§æ)",
            'address': r"(?:‡§Æ‡•à‡§Ç|‡§™‡§§‡§æ|‡§®‡§ø‡§µ‡§æ‡§∏)\s+([^\.]{10,100})(?:‡§Æ‡•á‡§Ç ‡§∞‡§π‡§§‡§æ ‡§π‡•Ç‡§Å|‡§Æ‡•á‡§Ç ‡§∞‡§π‡§§‡•Ä ‡§π‡•Ç‡§Å|‡§™‡§∞ ‡§∞‡§π‡§§‡§æ ‡§π‡•Ç‡§Å|‡§™‡§∞ ‡§∞‡§π‡§§‡•Ä ‡§π‡•Ç‡§Å|\‡§Æ‡•á‡§Ç ‡§®‡§ø‡§µ‡§æ‡§∏ ‡§ï‡§∞‡§§‡§æ|‡§Æ‡•á‡§Ç ‡§®‡§ø‡§µ‡§æ‡§∏ ‡§ï‡§∞‡§§‡•Ä)",
            'location': r"(?:‡§™‡§æ‡§∏|‡§Æ‡•á‡§Ç|‡§ï‡•á ‡§®‡§ø‡§ï‡§ü)\s+([^\.]+?)(?:‡§ú‡§¨|‡§ú‡§π‡§æ‡§Å|\.)",
            'witness': r"([^\.\,]+)(?:‡§®‡•á ‡§¶‡•á‡§ñ‡§æ|‡§ó‡§µ‡§æ‡§π)",
            'accused': r"(?:‡§Ü‡§∞‡•ã‡§™‡•Ä|‡§∏‡§Ç‡§¶‡§ø‡§ó‡•ç‡§ß|‡§π‡§Æ‡§≤‡§æ‡§µ‡§∞)\s+([^\.]{5,100})(?:\.|\n)",
            'stolen': r"(?:‡§ö‡•ã‡§∞‡•Ä|‡§≤‡•Ç‡§ü|‡§õ‡•Ä‡§®)\s+([^\.]{5,100})(?:\.|\n)",
            'value': r"(?:‡§ï‡•Ä‡§Æ‡§§|‡§Æ‡•Ç‡§≤‡•ç‡§Ø|‡§≤‡§æ‡§ó‡§§)\s+(?:‡§∞‡•Å\.?|‚Çπ)?\s*([0-9,]+)"
        },
        'punjabi': {
            'name': r"(?:‡®Æ‡©á‡®∞‡®æ ‡®®‡®æ‡®Æ|‡®Æ‡©à‡®Ç)\s+([^\.\,]+)[\.\,]",
            'father': r"(?:‡®Æ‡©á‡®∞‡©á ‡®™‡®ø‡®§‡®æ ‡®¶‡®æ ‡®®‡®æ‡®Æ|‡®™‡®ø‡®§‡®æ ‡®¶‡®æ ‡®®‡®æ‡®Æ|‡®™‡®ø‡®§‡®æ ‡®ú‡©Ä ‡®¶‡®æ ‡®®‡®æ‡®Æ)\s+([^\.\,]+)[\.\,]",
            'husband': r"(?:‡®Æ‡©á‡®∞‡©á ‡®™‡®§‡©Ä ‡®¶‡®æ ‡®®‡®æ‡®Æ|‡®™‡®§‡©Ä ‡®¶‡®æ ‡®®‡®æ‡®Æ)\s+([^\.\,]+)[\.\,]",
            'dob': r"(?:‡®ú‡®®‡®Æ ‡®Æ‡®ø‡®§‡©Ä|‡®ú‡®®‡®Æ ‡®¶‡®ø‡®®)\s+([0-9]{1,2}\s+(?:‡®ú‡®®‡®µ‡®∞‡©Ä|‡®´‡®∞‡®µ‡®∞‡©Ä|‡®Æ‡®æ‡®∞‡®ö|‡®Ö‡®™‡©ç‡®∞‡©à‡®≤|‡®Æ‡®à|‡®ú‡©Ç‡®®|‡®ú‡©Å‡®≤‡®æ‡®à|‡®Ö‡®ó‡®∏‡®§|‡®∏‡®§‡©∞‡®¨‡®∞|‡®Ö‡®ï‡®§‡©Ç‡®¨‡®∞|‡®®‡®µ‡©∞‡®¨‡®∞|‡®¶‡®∏‡©∞‡®¨‡®∞)(?:\s+[0-9]{4})?)",
            'nationality': r"(?:‡®Æ‡©á‡®∞‡©Ä ‡®®‡®æ‡®ó‡®∞‡®ø‡®ï‡®§‡®æ|‡®ï‡©å‡®Æ‡©Ä‡®Ö‡®§)\s+([^\.\,]+)",
            'occupation': r"(?:‡®Æ‡©à‡®Ç|‡®Æ‡©á‡®∞‡®æ ‡®ï‡®ø‡©±‡®§‡®æ|‡®™‡©á‡®∏‡®º‡®æ)\s+([^\.\,]{3,30})(?:‡®π‡®æ‡®Ç|‡®π‡©à|‡®µ‡®ø‡©±‡®ö|‡®¶‡®æ)",
            'address': r"(?:‡®Æ‡©à‡®Ç|‡®™‡®§‡®æ|‡®®‡®ø‡®µ‡®æ‡®∏)\s+([^\.]{10,100})(?:‡®µ‡®ø‡©±‡®ö ‡®∞‡®π‡®ø‡©∞‡®¶‡®æ ‡®π‡®æ‡®Ç|‡®µ‡®ø‡©±‡®ö ‡®∞‡®π‡®ø‡©∞‡®¶‡©Ä ‡®π‡®æ‡®Ç|'‡®§‡©á ‡®∞‡®π‡®ø‡©∞‡®¶‡®æ ‡®π‡®æ‡®Ç|'‡®§‡©á ‡®∞‡®π‡®ø‡©∞‡®¶‡©Ä ‡®π‡®æ‡®Ç|‡®µ‡®ø‡©±‡®ö ‡®®‡®ø‡®µ‡®æ‡®∏ ‡®ï‡®∞‡®¶‡®æ|‡®µ‡®ø‡©±‡®ö ‡®®‡®ø‡®µ‡®æ‡®∏ ‡®ï‡®∞‡®¶‡©Ä)",
            'location': r"(?:‡®®‡©á‡©ú‡©á|‡®µ‡®ø‡©±‡®ö|‡®ï‡©ã‡®≤)\s+([^\.]+?)(?:‡®ú‡®¶‡©ã‡®Ç|‡®ú‡®ø‡©±‡®•‡©á|\.)",
            'witness': r"([^\.\,]+)(?:‡®®‡©á ‡®µ‡©á‡®ñ‡®ø‡®Ü|‡®ó‡®µ‡®æ‡®π)",
            'accused': r"(?:‡®¶‡©ã‡®∏‡®º‡©Ä|‡®∏‡®º‡©±‡®ï‡©Ä|‡®π‡®Æ‡®≤‡®æ‡®µ‡®∞)\s+([^\.]{5,100})(?:\.|\\n)",
            'stolen': r"(?:‡®ö‡©ã‡®∞‡©Ä|‡®≤‡©Å‡©±‡®ü|‡®ñ‡©ã‡®π)\s+([^\.]{5,100})(?:\.|\\n)",
            'value': r"(?:‡®ï‡©Ä‡®Æ‡®§|‡®Æ‡©Å‡©±‡®≤|‡®≤‡®æ‡®ó‡®§)\s+(?:‡®∞‡©Å\.?|‚Çπ)?\s*([0-9,]+)"
        }
    }
    
    patterns_for_lang = patterns.get(language.lower(), patterns['english'])
    
    # Extract name
    name_match = re.search(patterns_for_lang['name'], transcribed_text, re.IGNORECASE)
    if name_match:
        info["victim_name"] = name_match.group(1).strip()
    
    # Extract father's or husband's name
    father_match = re.search(patterns_for_lang['father'], transcribed_text, re.IGNORECASE)
    husband_match = re.search(patterns_for_lang['husband'], transcribed_text, re.IGNORECASE)
    if father_match:
        info["father_or_husband_name"] = father_match.group(1).strip()
    elif husband_match:
        info["father_or_husband_name"] = husband_match.group(1).strip()
    
    # Extract date of birth
    dob_match = re.search(patterns_for_lang['dob'], transcribed_text, re.IGNORECASE)
    if dob_match:
        info["dob"] = dob_match.group(1).strip()
    
    # Extract nationality
    nationality_match = re.search(patterns_for_lang['nationality'], transcribed_text, re.IGNORECASE)
    if nationality_match:
        info["nationality"] = nationality_match.group(1).strip()
    
    # Extract occupation
    occupation_match = re.search(patterns_for_lang['occupation'], transcribed_text, re.IGNORECASE)
    if occupation_match:
        info["occupation"] = occupation_match.group(1).strip()
    
    # Extract address
    address_match = re.search(patterns_for_lang['address'], transcribed_text, re.IGNORECASE)
    if address_match:
        info["address"] = address_match.group(1).strip()
        
    # Extract date and time - using universal patterns as they're typically numeric
    date_match = re.search(r"(\d+(?:st|nd|rd|th)?\s+(?:January|February|March|April|May|June|July|August|September|October|November|December)|(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\s+\d+)(?:\s+\d{4})?", transcribed_text, re.IGNORECASE)
    time_match = re.search(r"(?:at|around|approximately)\s+(\d{1,2}(?::\d{2})?\s*(?:am|pm|AM|PM|a\.m\.|p\.m\.|hours))", transcribed_text, re.IGNORECASE)
    
    if date_match:
        info["incident_date"] = date_match.group(1).strip()
    if time_match:
        info["incident_time"] = time_match.group(1).strip()
    
    # Extract location
    location_match = re.search(patterns_for_lang['location'], transcribed_text, re.IGNORECASE)
    if location_match:
        info["incident_location"] = location_match.group(1).strip()
    
    # Extract witness details
    witness_match = re.search(patterns_for_lang['witness'], transcribed_text, re.IGNORECASE)
    if witness_match:
        info["witness_details"] = witness_match.group(1).strip()
    
    # Extract accused description
    accused_match = re.search(patterns_for_lang['accused'], transcribed_text, re.IGNORECASE)
    if accused_match:
        info["accused_description"] = accused_match.group(1).strip()
    
    # Extract stolen properties
    stolen_match = re.search(patterns_for_lang['stolen'], transcribed_text, re.IGNORECASE)
    if stolen_match:
        info["stolen_properties"] = stolen_match.group(1).strip()
    else:
        # Fallback to keywords approach if regex doesn't find anything
        stolen_keywords = {
            'english': ['phone', 'mobile', 'wallet', 'bag', 'purse', 'money', 'jewelry', 'cash', 'gold', 'silver', 'laptop', 'watch'],
            'hindi': ['‡§´‡•ã‡§®', '‡§Æ‡•ã‡§¨‡§æ‡§á‡§≤', '‡§™‡§∞‡•ç‡§∏', '‡§¨‡§ü‡•Å‡§Ü', '‡§™‡•à‡§∏‡•á', '‡§ó‡§π‡§®‡•á', '‡§®‡§ó‡§¶‡•Ä', '‡§∏‡•ã‡§®‡§æ', '‡§ö‡§æ‡§Ç‡§¶‡•Ä', '‡§≤‡•à‡§™‡§ü‡•â‡§™', '‡§ò‡§°‡§º‡•Ä'],
            'punjabi': ['‡®´‡©ã‡®®', '‡®Æ‡©ã‡®¨‡®æ‡®à‡®≤', '‡®™‡®∞‡®∏', '‡®¨‡®ü‡©Ç‡®Ü', '‡®™‡©à‡®∏‡©á', '‡®ó‡®π‡®ø‡®£‡©á', '‡®®‡®ï‡®¶‡©Ä', '‡®∏‡©ã‡®®‡®æ', '‡®ö‡®æ‡®Ç‡®¶‡©Ä', '‡®≤‡©à‡®™‡®ü‡®æ‡®™', '‡®ò‡©ú‡©Ä']
        }
        
        stolen_items = []
        for keyword in stolen_keywords.get(language.lower(), stolen_keywords['english']):
            if keyword.lower() in transcribed_text.lower():
                stolen_items.append(keyword)
        
        if stolen_items:
            info["stolen_properties"] = ", ".join(stolen_items)
    
    # Extract total value
    value_match = re.search(patterns_for_lang['value'], transcribed_text, re.IGNORECASE)
    if value_match:
        info["total_value"] = value_match.group(1).strip()
    
    # Extract delay reason
    delay_reason_match = re.search(r"(?:delay|late|couldn't report|could not report|waited)(?:[^.]{5,100})(?:\.|\n)", transcribed_text, re.IGNORECASE)
    if delay_reason_match:
        info["delay_reason"] = delay_reason_match.group(0).strip()
    
    return info

def transcribe_audio(audio_path, language='english'):
    """Convert audio to text using Whisper."""
    try:
        # Language codes for Whisper
        language_codes = {
            'english': 'en',
            'hindi': 'hi',
            'punjabi': 'pa'
        }
        
        if not audio_path or not os.path.exists(audio_path):
            return {
                "success": False,
                "error": f"Audio file not found at path: {audio_path}"
            }

        # Check file size and format
        if os.path.getsize(audio_path) == 0:
            return {
                "success": False,
                "error": "Audio file is empty"
            }
            
        # Use GPU if available for transcription
        try:
            result = model.transcribe(
                audio_path, 
                fp16=(device == "cuda"),
                language=language_codes.get(language.lower(), 'en')
            )
        except Exception as e:
            return {
                "success": False,
                "error": f"Whisper transcription failed: {str(e)}"
            }

        if not result or not result.get("text"):
            return {
                "success": False,
                "error": "No transcription result produced"
            }

        transcribed_text = result["text"]
        # Extract personal information from transcribed text
        personal_info = extract_personal_info(transcribed_text, language)
        
        return {
            "success": True,
            "text": transcribed_text,
            "personal_info": personal_info,
            "language": language
        }
    except Exception as e:
        return {
            "success": False,
            "error": f"Error during transcription process: {str(e)}"
        }

def analyze_sentiment_and_crime(transcription_result):
    """Analyzes sentiment and predicts crime type from transcribed text."""
    
    # Handle transcription errors
    if isinstance(transcription_result, dict):
        if not transcription_result.get("success", False):
            return {"error": transcription_result.get("error", "Transcription failed")}
        transcribed_text = transcription_result.get("text", "")
    else:
        transcribed_text = str(transcription_result)

    if not transcribed_text.strip():
        return {"error": "Empty text provided."}

    try:
        # üîπ Step 1: Sentiment Analysis
        sentiment_result = sentiment_analyzer(transcribed_text)[0]  # Extract first result

        # üîπ Step 2: Crime Type Prediction
        crime_labels = ["Theft", "Assault", "Fraud", "Harassment", "Murder", "Kidnapping"]
        intent_result = classifier(transcribed_text, crime_labels, multi_label=True)

        # Extract top crime predictions
        crime_predictions = [
            {"crime": label, "score": round(score, 4)}
            for label, score in zip(intent_result["labels"], intent_result["scores"])
        ]

        return {
            "sentiment": sentiment_result,
            "crime_predictions": crime_predictions
        }

    except Exception as e:
        return {"error": f"Analysis failed: {str(e)}"}
